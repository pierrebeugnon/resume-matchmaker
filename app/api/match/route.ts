import { NextRequest, NextResponse } from 'next/server'
import Groq from 'groq-sdk'
import type { MatchingRequest, MatchingResponse, CandidateCV, MatchingResult } from '@/lib/types'

// Initialize Groq client
const groq = new Groq({ apiKey: process.env.GROQ_API_KEY })

// Groq model configuration
const GROQ_MODEL = process.env.GROQ_MODEL || 'llama-3.3-70b-versatile'

export async function POST(request: NextRequest) {
  try {
    const body: MatchingRequest = await request.json()
    
    console.log(`üì• API re√ßoit ${body.cv_list?.length || 0} CVs √† analyser`)
    console.log(`üìù Poste: ${body.job_offer?.title}`)
    console.log(`üéØ Description (premiers 100 car): ${body.job_offer?.description?.substring(0, 100)}...`)
    
    // Validate input
    if (!body.job_offer || !body.cv_list || body.cv_list.length === 0) {
      return NextResponse.json(
        { error: 'Invalid request: job_offer and cv_list are required' },
        { status: 400 }
      )
    }

    let matchingResult: MatchingResponse

    try {
      console.log(`Using Groq model: ${GROQ_MODEL}`)
      
      // Traiter par batch de 5 CVs maximum pour √©viter les limites de tokens
      const BATCH_SIZE = 5
      const batches: CandidateCV[][] = []
      
      for (let i = 0; i < body.cv_list.length; i += BATCH_SIZE) {
        batches.push(body.cv_list.slice(i, i + BATCH_SIZE))
      }
      
      console.log(`üì¶ Traitement en ${batches.length} batch(s) de max ${BATCH_SIZE} CVs`)
      
      // Traiter chaque batch
      const allResults: MatchingResult[] = []
      const batchSummaries: string[] = []
      
      for (let i = 0; i < batches.length; i++) {
        console.log(`   Batch ${i + 1}/${batches.length}: ${batches[i].length} CVs...`)
        
        const batchBody: MatchingRequest = {
          ...body,
          cv_list: batches[i]
        }
        
        const batchResult = await matchWithGroq(batchBody)
        allResults.push(...batchResult.results)
        if (batchResult.summary) {
          batchSummaries.push(batchResult.summary)
        }
      }
      
      // D√©dupliquer les r√©sultats (au cas o√π un candidat appara√Æt dans plusieurs batchs)
      const uniqueResults = new Map<string, MatchingResult>()
      allResults.forEach(result => {
        // Garder le meilleur score si duplicata
        const existing = uniqueResults.get(result.candidate_name)
        if (!existing || result.relevance_score > existing.relevance_score) {
          uniqueResults.set(result.candidate_name, result)
        }
      })
      
      const dedupedResults = Array.from(uniqueResults.values())
      
      // G√©n√©rer un r√©sum√© qualitatif global
      const excellentCandidates = dedupedResults.filter(r => r.relevance_score >= 80)
      const goodCandidates = dedupedResults.filter(r => r.relevance_score >= 60 && r.relevance_score < 80)
      const moderateCandidates = dedupedResults.filter(r => r.relevance_score >= 40 && r.relevance_score < 60)
      
      let globalSummary = ''
      
      if (excellentCandidates.length > 0) {
        const topNames = excellentCandidates.slice(0, 3).map(c => c.candidate_name).join(', ')
        globalSummary += `üåü Excellentes correspondances : ${excellentCandidates.length} candidat(s) avec un score sup√©rieur √† 80%. Les profils les plus pertinents sont ${topNames}. `
      }
      
      if (goodCandidates.length > 0) {
        globalSummary += `‚úÖ Bonnes correspondances : ${goodCandidates.length} candidat(s) avec un score entre 60% et 80%, pr√©sentant des comp√©tences solides avec quelques formations √† pr√©voir. `
      }
      
      if (moderateCandidates.length > 0) {
        globalSummary += `‚ö†Ô∏è Correspondances mod√©r√©es : ${moderateCandidates.length} candidat(s) avec un score entre 40% et 60%, n√©cessitant un accompagnement plus important. `
      }
      
      // Ajouter une analyse des comp√©tences les plus demand√©es vs trouv√©es
      const allMatchingSkills = dedupedResults.flatMap(r => r.matching_skills || [])
      const skillCounts = allMatchingSkills.reduce((acc, skill) => {
        acc[skill] = (acc[skill] || 0) + 1
        return acc
      }, {} as Record<string, number>)
      
      const topSkills = Object.entries(skillCounts)
        .sort(([, a], [, b]) => b - a)
        .slice(0, 5)
        .map(([skill]) => skill)
      
      if (topSkills.length > 0) {
        globalSummary += `\n\nüîë Comp√©tences les plus repr√©sent√©es dans le pool : ${topSkills.join(', ')}.`
      }
      
      matchingResult = {
        results: dedupedResults,
        summary: globalSummary || `${dedupedResults.length} candidats analys√©s avec succ√®s`
      }
      
      console.log(`‚úÖ Total: ${allResults.length} r√©sultats bruts ‚Üí ${dedupedResults.length} candidats uniques analys√©s`)
      if (allResults.length > dedupedResults.length) {
        console.warn(`‚ö†Ô∏è ${allResults.length - dedupedResults.length} duplications d√©tect√©es et supprim√©es`)
      }
      
      // Identifier les candidats manquants
      if (dedupedResults.length < body.cv_list.length) {
        console.warn(`\n‚ö†Ô∏è ${body.cv_list.length - dedupedResults.length} candidat(s) manquant(s) apr√®s traitement complet:`)
        body.cv_list.forEach(cv => {
          const found = dedupedResults.find(r => r.candidate_name === cv.name)
          if (!found) {
            console.warn(`   ‚ùå ${cv.name} (${cv.job_title}) - NON ANALYS√â`)
          }
        })
      } else {
        console.log(`‚úÖ Tous les ${body.cv_list.length} candidats ont √©t√© analys√©s avec succ√®s!`)
      }
      
    } catch (groqError) {
      console.error('Groq error:', groqError)
      return NextResponse.json(
        { error: 'Erreur lors du matching. V√©rifiez votre configuration Groq.' },
        { status: 500 }
      )
    }
    
    return NextResponse.json(matchingResult)
  } catch (error) {
    console.error('Error in matching API:', error)
    return NextResponse.json(
      { error: 'Internal server error' },
      { status: 500 }
    )
  }
}

async function matchWithGroq(body: MatchingRequest): Promise<MatchingResponse> {
  const systemPrompt = getSystemPrompt(body.weights)
  const userPrompt = buildLLMPrompt(body)
  
  // Use Groq chat completion API
  const response = await groq.chat.completions.create({
    model: GROQ_MODEL,
    messages: [
      { role: "system", content: systemPrompt },
      { role: "user", content: `${userPrompt}\n\nRappel : Retourne UNIQUEMENT du JSON valide dans le format exact sp√©cifi√©, sans autre texte. Toutes les explications en fran√ßais.` }
    ],
    max_tokens: 4000, // Augment√© pour traiter jusqu'√† 10 CVs par batch
    temperature: 0.3,
  })
  
  // Extract the response text
  let responseText = response.choices[0]?.message?.content || ''
  responseText = responseText.trim()
  
  // Try to extract JSON from the response (in case it's wrapped in markdown code blocks)
  const codeBlockMatch = responseText.match(/```(?:json)?\s*([\s\S]*?)\s*```/)
  if (codeBlockMatch) {
    responseText = codeBlockMatch[1].trim()
  } else {
    // Try to extract JSON object directly
    const jsonMatch = responseText.match(/\{[\s\S]*\}/)
    if (jsonMatch) {
      responseText = jsonMatch[0]
    }
  }
  
  try {
    const matchingResult: MatchingResponse = JSON.parse(responseText)
    
    // Validate the response structure
    if (!matchingResult.results || !Array.isArray(matchingResult.results)) {
      throw new Error('Invalid response structure')
    }
    
    // LOG D√âTAILL√â pour debug
    console.log(`\nüìä API a re√ßu ${body.cv_list.length} CVs`)
    console.log(`‚úÖ IA a retourn√© ${matchingResult.results.length} r√©sultats\n`)
    console.log('=== MATCHING RESULTS DEBUG ===')
    matchingResult.results.forEach((result, index) => {
      console.log(`\n${index + 1}. ${result.candidate_name}:`)
      console.log(`   Score: ${result.relevance_score}%`)
      console.log(`   Reasoning: ${result.reasoning}`)
      console.log(`   Matching skills: ${result.matching_skills?.join(', ') || 'none'}`)
      console.log(`   Missing skills: ${result.missing_skills?.join(', ') || 'none'}`)
    })
    console.log('=== END DEBUG ===\n')
    
    // Si l'IA n'a pas retourn√© tous les candidats
    if (matchingResult.results.length < body.cv_list.length) {
      console.warn(`‚ö†Ô∏è ATTENTION: L'IA n'a retourn√© que ${matchingResult.results.length}/${body.cv_list.length} candidats !`)
      console.warn(`   Candidats manquants dans la r√©ponse de l'IA:`)
      body.cv_list.forEach(cv => {
        const found = matchingResult.results.find(r => r.candidate_name === cv.name)
        if (!found) {
          console.warn(`   - ${cv.name} (${cv.job_title})`)
        }
      })
    }
    
    return matchingResult
  } catch (parseError) {
    console.error('Failed to parse Groq response:', responseText)
    console.error('Parse error:', parseError)
    throw new Error('Invalid JSON response from Groq')
  }
}

function getSystemPrompt(weights?: { technicalSkills: number; experience: number; training: number; context: number }): string {
  // Utiliser les pond√©rations par d√©faut si non fournies
  const w = weights || { technicalSkills: 40, experience: 30, training: 20, context: 10 }
  
  return `Tu es un assistant expert en recrutement sp√©cialis√© dans le matching s√©mantique entre des appels d'offres (AO) et des profils de candidats (CVs).
L'objectif est d'aider une application de recrutement √† recommander les meilleurs profils de candidats pour une offre d'emploi donn√©e en utilisant une analyse s√©mantique approfondie.

T√¢che :
Analyser l'offre d'emploi fournie et la liste des CVs candidats pour attribuer √† chaque candidat un score de pertinence et une explication courte EN FRAN√áAIS.

IMPORTANT - MATCHING S√âMANTIQUE ET RECONNAISSANCE DES √âQUIVALENCES :
Tu DOIS appliquer une analyse s√©mantique intelligente qui reconna√Æt :

1. **R√¥les et Titres √âquivalents/Connexes** :
   - "Data Engineer" ‚âà "Data Architect", "Data Platform Engineer", "Analytics Engineer", "ML Engineer"
   - "DevOps Engineer" ‚âà "SRE", "Platform Engineer", "Cloud Engineer", "Infrastructure Engineer"
   - "Full Stack Developer" ‚âà "Software Engineer", "Web Developer", "Application Developer"
   - "Product Manager" ‚âà "Product Owner", "Technical Product Manager"
   - Etc. (applique le m√™me principe √† tous les r√¥les)

2. **Comp√©tences Techniques √âquivalentes** :
   - Technologies de m√™me famille : Python ‚âà Java ‚âà Go (langages backend)
   - Outils similaires : Terraform ‚âà CloudFormation ‚âà Pulumi (IaC)
   - Frameworks √©quivalents : React ‚âà Vue ‚âà Angular (frontend)
   - Bases de donn√©es : PostgreSQL ‚âà MySQL ‚âà Oracle (SQL), MongoDB ‚âà Cassandra (NoSQL)
   - Cloud : AWS ‚âà Azure ‚âà GCP (comp√©tences cloud transf√©rables)

3. **Domaines et Concepts Connexes** :
   - "Data Mesh", "Domain-Driven Design", "Data Products" ‚Üí concepts avanc√©s de Data Engineering
   - "Kubernetes", "Docker", "Helm" ‚Üí orchestration de containers
   - "CI/CD", "Jenkins", "GitLab CI" ‚Üí DevOps practices
   - "dbt", "Airflow", "Dagster" ‚Üí data orchestration

4. **Comp√©tences Transf√©rables** :
   - Un "Data Architect" avec dbt, Kafka, Kubernetes poss√®de des comp√©tences TR√àS pertinentes pour Data Engineer
   - Un "Senior Engineer" dans un domaine peut √™tre pertinent pour un r√¥le similaire dans un autre
   - L'exp√©rience dans des architectures complexes est valorisable

Crit√®res de matching principaux (avec pond√©ration PERSONNALIS√âE) :
- **Comp√©tences techniques** (${w.technicalSkills}%) : Matching s√©mantique des skills, technologies similaires, comp√©tences transf√©rables
- **Exp√©rience professionnelle** (${w.experience}%) : Ann√©es d'exp√©rience, projets similaires, r√¥les connexes
- **Formations & Certifications** (${w.training}%) : Dipl√¥mes pertinents, certifications valorisables
- **Contexte & Secteur** (${w.context}%) : Secteurs d'activit√© pertinents

IMPORTANT : Utilise EXACTEMENT ces pond√©rations (${w.technicalSkills}%/${w.experience}%/${w.training}%/${w.context}%) pour calculer le score final de chaque candidat.

R√àGLES DE SCORING :
- Ne JAMAIS attribuer 0% √† un candidat qui a des comp√©tences ou une exp√©rience pertinentes
- Un score de 0% est UNIQUEMENT pour un profil totalement hors sujet (ex: un comptable pour un poste d'ing√©nieur logiciel)
- M√™me sans correspondance exacte du titre, un candidat avec des comp√©tences techniques pertinentes m√©rite au minimum 40-50%
- Un candidat avec 50%+ des comp√©tences requises et un r√¥le connexe devrait obtenir 60-80%
- Valoriser les architectures avanc√©es et concepts modernes (Data Mesh, Microservices, Cloud Native, etc.)

Format de sortie attendu (JSON) :
{
  "results": [
    {
      "candidate_name": "Pr√©nom Nom",
      "relevance_score": 0-100,
      "reasoning": "Explication br√®ve du score en fran√ßais : ad√©quation du poste, comp√©tences (y compris √©quivalences s√©mantiques reconnues), exp√©rience, secteurs.",
      "matching_skills": ["comp√©tence1", "comp√©tence2", "comp√©tence3"],
      "missing_skills": ["comp√©tence4", "comp√©tence5"],
      "sectors": ["Secteur1", "Secteur2"]
    }
  ],
  "summary": "Aper√ßu court des meilleurs candidats et insights cl√©s en fran√ßais"
}

R√®gles suppl√©mentaires :
- Ne jamais inventer de donn√©es non trouv√©es dans les CVs.
- Toujours expliquer EN FRAN√áAIS la logique derri√®re chaque score, en mentionnant les √©quivalences s√©mantiques reconnues.
- Prendre en compte les secteurs d'activit√© dans l'√©valuation (bonus si pertinent pour le poste).
- La r√©ponse doit √™tre uniquement du JSON valide (pas de texte en dehors du JSON).
- Toutes les explications (reasoning, summary) doivent √™tre r√©dig√©es en fran√ßais.
- PENSER S√âMANTIQUEMENT : un Data Architect avec dbt, Kafka, Kubernetes est TR√àS pertinent pour Data Engineer !`
}

function buildLLMPrompt(request: MatchingRequest): string {
  return `Analyse l'offre d'emploi suivante et les CVs des candidats :

Offre d'Emploi :
- Titre : ${request.job_offer.title}
- Description compl√®te : ${request.job_offer.description}
- Exp√©rience Minimale : ${request.job_offer.min_experience} ans

IMPORTANT : Tu dois ANALYSER LA DESCRIPTION pour identifier :
1. Les comp√©tences techniques requises (explicites ET implicites)
2. Les comp√©tences fonctionnelles et m√©tiers
3. Les technologies, outils, frameworks, langages pertinents
4. Les concepts et architectures mentionn√©s

Candidats :
${request.cv_list.map((cv, index) => `
${index + 1}. ${cv.name}
   - Poste : ${cv.job_title}
   - Comp√©tences : ${cv.skills.join(', ')}
   - Ann√©es d'Exp√©rience : ${cv.years_experience}
   - Secteurs d'activit√© : ${cv.sectors && cv.sectors.length > 0 ? cv.sectors.join(', ') : 'Non sp√©cifi√©'}
`).join('\n')}

INSTRUCTIONS DE MATCHING :
1. Extrais TOUTES les comp√©tences pertinentes de la description du poste (ne te limite pas √† une liste pr√©d√©finie)
2. Pour chaque candidat, identifie les comp√©tences qui matchent (y compris √©quivalences s√©mantiques)
3. Identifie les comp√©tences manquantes importantes
4. Applique le matching s√©mantique pour reconna√Ætre les r√¥les et comp√©tences connexes
5. Calcule un score r√©aliste bas√© sur les pond√©rations fournies

‚ö†Ô∏è CRITIQUE : Tu DOIS retourner EXACTEMENT ${request.cv_list.length} r√©sultats dans le JSON, un pour CHAQUE candidat list√© ci-dessus.
N'omets AUCUN candidat, m√™me si le score est 0%. Chaque candidat doit avoir une entr√©e dans le tableau "results".

N'oublie pas : toutes les explications doivent √™tre EN FRAN√áAIS et d√©tailler les √©quivalences s√©mantiques reconnues.`
}
